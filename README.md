# Run Llama3.1 70b parameters on openshift

- For deploying Llama-3.1-70b using 4bit AWQ qunantization , using vLLM inference, [Click here](./llama3.1-70b-vllm/README.md)
- For deploying Llama-3.1-70b using 4bit AWQ qunantization , using TGI(Huggin Face' Text Generation Interface) inference, [Click here](./llama3.1-70b-tgi/README.md)
